{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "! curl -L -o ./Downloads/imgdt.zip\\  https://www.kaggle.com/api/v1/datasets/download/rhtsingh/130k-images-512x512-universal-image-embeddings\n",
    "! unzip ./Downloads/imgdt.zip\n",
    "! rm ./Downloads/imgdt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from vae import VAE\n",
    "from unet import UNet\n",
    "from diffusion import Diffusion\n",
    "\n",
    "class InpaintingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, image_size=256):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        self.image_files = [f for f in os.listdir(data_dir) if f.endswith('.png')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        return self.transform(image)\n",
    "\n",
    "def prepare_data(data_dir, batch_size=32, val_split=0.2):\n",
    "    full_dataset = InpaintingDataset(data_dir)\n",
    "    val_size = int(len(full_dataset) * val_split)\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def generate_mask(batch_size, img_size=512, device='cuda'):\n",
    "    masks = torch.ones((batch_size, 1, img_size, img_size), device=device)\n",
    "    for i in range(batch_size):\n",
    "        w, h = img_size, img_size\n",
    "        mask_width = int(w * np.random.uniform(0.1, 0.5))\n",
    "        mask_height = int(h * np.random.uniform(0.1, 0.5))\n",
    "        x = np.random.randint(0, w - mask_width)\n",
    "        y = np.random.randint(0, h - mask_height)\n",
    "        masks[i, :, y:y+mask_height, x:x+mask_width] = 0\n",
    "    return masks\n",
    "\n",
    "def train_model(data_dir, epochs=100, batch_size=32, lr=1e-4, save_dir='checkpoints'):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader, val_loader = prepare_data(data_dir, batch_size)\n",
    "    \n",
    "    vae = VAE().to(device)\n",
    "    unet = UNet().to(device)\n",
    "    \n",
    "    # TensorBoard setup\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = os.path.join('runs', current_time)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    \n",
    "    vae_path = os.path.join(save_dir, 'vae.pth')\n",
    "    if os.path.exists(vae_path):\n",
    "        vae.load_state_dict(torch.load(vae_path))\n",
    "        print(\"Loaded pretrained VAE\")\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(unet.parameters(), lr=lr)\n",
    "    diffusion = Diffusion()\n",
    "    best_val_loss = float('inf')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        unet.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, images in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            masks = generate_mask(images.size(0), device=device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                z_mean, z_logvar = vae.encode(images)\n",
    "                z = vae.reparameterize(z_mean, z_logvar)\n",
    "            \n",
    "            t = diffusion.sample_timesteps(z.size(0), device)\n",
    "            z_noisy, noise = diffusion.add_noise(z, t, device)\n",
    "            z_masked = z * (1 - masks) + z_noisy * masks\n",
    "            \n",
    "            unet_input = torch.cat([z_masked, masks], dim=1)\n",
    "            predicted_noise = unet(unet_input, t)\n",
    "            \n",
    "            loss = F.mse_loss(predicted_noise * masks, noise * masks)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(images)}/{len(train_loader.dataset)} '\n",
    "                      f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "            \n",
    "            # Log to TensorBoard\n",
    "            writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "        \n",
    "        # Validation phase\n",
    "        unet.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images in val_loader:\n",
    "                images = images.to(device)\n",
    "                masks = generate_mask(images.size(0), device=device)\n",
    "                z_mean, z_logvar = vae.encode(images)\n",
    "                z = vae.reparameterize(z_mean, z_logvar)\n",
    "                t = diffusion.sample_timesteps(z.size(0), device)\n",
    "                z_noisy, noise = diffusion.add_noise(z, t, device)\n",
    "                z_masked = z * (1 - masks) + z_noisy * masks\n",
    "                unet_input = torch.cat([z_masked, masks], dim=1)\n",
    "                predicted_noise = unet(unet_input, t)\n",
    "                val_loss += F.mse_loss(predicted_noise * masks, noise * masks).item()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch} Summary:')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Training Loss (Epoch)', train_loss, epoch)\n",
    "        writer.add_scalar('Validation Loss (Epoch)', val_loss, epoch)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(unet.state_dict(), os.path.join(save_dir, 'unet_best.pth'))\n",
    "            print('Saved best model!')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(unet.state_dict(), os.path.join(save_dir, f'unet_epoch_{epoch}.pth'))\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    writer.close()\n",
    "\n",
    "# def main():\n",
    "data_dir = input(\"Please enter the path to your data directory: \")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "save_dir = 'checkpoints'\n",
    "\n",
    "train_model(\n",
    "    data_dir=data_dir,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=learning_rate,\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
